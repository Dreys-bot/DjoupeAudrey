---
layout: '@/templates/BasePost.astro'
title: 3D Generative Adversial Model Part 2 - Wasserstein GAN Improvement
description: This article compares two adversarial generative models (standard GANs and WGANs). The goal is to understand how these competing networks can produce synthetic data in an unsupervised manner. We will look at how WGAN improves training stability, a key challenge in the field of generative learning.
pubDate: 2023-12-05T00:00:00Z
imgSrc: '/assets/images/3DGAN-2/index.jpeg'
imgAlt: 'Image post 3'
---

This post is to study  **generation and reconstruction 3D shapes** with **3D-IWGAN(3D-Improved Wassertein GAN)**. It is an improved GAN model approach and used voxelized objects from dataset to train deep generator and discriminator networks.

|Method   |3D-IWGAN |
|---------|---------|
|3D model |voxels|
|Objective|-3D Generation <br></br> -3D Reconstruction|
|Architecture|main architecture using GAN and an additional VAE to encode  the image  to latent vectors|
|           |Input = RGB images or depth images|
|     |Encoder|
|     |normally distributed latent vectors|
|     |Generator = decoder|
|     |Output = 3D sample voxel models|
|     |Discriminator|
|     |Evaluate the output to improve training|

# Method
3D-IWGAN architecture utilizes voxelized objects from a data set to train deep generator and discriminator networks in tandem, with the goal of generating realistic 3D object shapes. It employs an improved version of the standard GAN, by exploiting the Wasserstein distance normalised with gradient penalization as a training objective. The following details the improvement that we made to the standard GAN in order to achieve WGAN first. After we will talk about the improvement of WGAN to be IWGAN.


> **Let's talk about what is WGAN model and his metricðŸ˜Š**. We begin with the metric because it will help you to understand how WGAN  works.

# Metrics of GAN and WGAN Model and differences

**1. Kullbackâ€“Leibler and Jensenâ€“Shannon Divergence**

Let us talk about two metrics for quantifying the similarity between two probability distributions.

(1)Â [KL (Kullbackâ€“Leibler) divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)Â measures how one probability distributionÂ ***p***Â diverges from a second expected probability distribution ***q***.

$D_{KL}(p||q) = \int_x \mathrm{p(x)}log\frac{p(x)}{q(x)}d_{x}$

D(KL) achieves the minimum zero whenÂ ***p(x)Â ==Â q(x)***Â everywhere. It is noticeable according to the formula that KL divergence is asymmetric. In cases whereÂ ***p(x)***Â is close to zero, butÂ ***q(x)***Â is significantly non-zero, theÂ ***qâ€™s*** effect is disregarded. It could cause buggy results when we just want to measure the similarity between two equally important distributions.

(2)Â [Jensenâ€“Shannon Divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)Â is another measure of similarity between two probability distributions, bounded byÂ [0,1]. JS divergence is symmetric and more smooth. 
![graph KL](/assets/images/3DGAN-2/graph_KL.png)

$D_{JS}(p||q) = \frac{1}{2}D_{KL}(p||\frac{p + q}{2}) + \frac{1}{2}D_{KL}(q||\frac{p + q}{2})$

Some believe ([Huszar, 2015](https://arxiv.org/pdf/1511.05101.pdf)) that one reason behind GANsâ€™ big success is switching the loss function from asymmetric KL divergence in traditional maximum-likelihood approach to symmetric JS divergence.

<u><b>**Small explanation about these metrics with examples**</u></b>

Let's take the example of an image generator that creates images of cats. You have a generator that generates cat images, and you also have a set of real cat images.

The KL (Kullback-Leibler) divergence metric quantifies the difference between the distribution of images generated by the generator and the distribution of real images. Let's assume you have two distributions: one corresponds to the distribution of images generated by the generator (let's call it P), and the other corresponds to the distribution of real images (let's call it Q). The KL divergence between P and Q measures how much information, on average, is needed to represent the differences between these two distributions. A higher value would indicate that the images generated by the generator are very different from the real images.

The KL divergence is not symmetric, which means that KL(P||Q) is not the same as KL(Q||P). This means that the way the generator approaches real images may be different from the way real images approach generated images. For example, it is possible for the generator to produce images that don't resemble real images at all, while real images may have similarities with the generated images.

On the other hand, the Jensen-Shannon (JS) divergence is a symmetric measure that compares the similarity between the two distributions. It uses the KL divergence to calculate a symmetric similarity measure. In other words, the JS divergence between P and Q is the same as the JS divergence between Q and P. A JS divergence value close to zero would indicate that the images generated by the generator are very similar to the real images.

By using the JS divergence, you can evaluate the performance of your generator by measuring the similarity between the generated images and the real images. If the JS divergence is low, it means that the generator is capable of producing images that are similar to the real images. If the JS divergence is high, it indicates that the images generated by the generator are very different from the real images.

In summary, the KL divergence measures the difference between the distributions of generated and real images, while the JS divergence measures the similarity between these distributions. These measures help you evaluate the performance of your generator by comparing it to the real objects you want to generate.

**2. EMD (earth's mover distance) or Wassertein distance for WGAN model**

The Earth Mover's Distance (EMD) is a method to evaluate dissimilarity between two multi-dimensional distributions in some feature space where a distance measure between single features, which we call theÂ _ground distance_Â is given.

The Wasserstein distance metric has several advantages over KL and JS divergences. 

- First, it is more stable and often facilitates the convergence of GAN model training. It also makes it possible to better take into account mass differences between distributions, which can be useful when the distributions have different images or modes.

- The Wasserstein distance metric has an interesting geometric interpretation. It can be thought of as the minimum amount of work required to move mass from one distribution to another, where each unit of mass is considered a "pile of dirt" and the cost of moving is determined by a cost function. This geometric interpretation gives it interesting properties in terms of stability and convergence.

<U><b>Small explanation about wasserstein metric with examples</u></b>

Suppose you have a random number generator and you want to compare it to a real distribution of numbers. Your generator produces random numbers, but you want to know how similar these numbers are to those in the real distribution.

The KL divergence would tell you how different the two distributions are. It would measure the amount of additional information needed to represent the differences between the two distributions. For example, if your generator primarily produces numbers between 0 and 10, while the actual distribution is centered around 100, the KL divergence would be high to indicate that the two distributions are very different.

JS divergence, on the other hand, would tell you how similar the two distributions are. If your generator produces numbers that closely resemble those in the real distribution, the JS divergence would be small, indicating high similarity between the two distributions.

Now let's look at the Wasserstein distance metric. She would tell you how much **work** is required to turn one distribution into another. In our example, this would mean how much effort you would have to put into transforming the distribution of numbers produced by your generator into the actual distribution of numbers. If the two distributions are very different, that would mean it would take a lot of work to make them similar.

To illustrate this, imagine that the actual distribution of numbers is a bell-shaped curve centered around 100. Your generator, on the other hand, mainly produces numbers between 0 and 10. The Wasserstein distance metric could tell you how many earth would need to be moved to transform the flat line between 0 and 10 into a curve of 100. The higher the Wasserstein distance metric, the more work would be required to perform this transformation. Look at the following figure to visualize what i am saying.
![wasserstein](/assets/images/3DGAN-2/Wasserstein.png)

# What is WGAN and how is different to GAN model?

Wasserstein Gan(WGAN) is an extension of the regular GAN that seeks an alternate way of training the generator model to better approximate the distribution of data observed in a given training dataset. It minimizes the approximation of the **earth's mover distance (em distance)** rather than the **jensen shannon divergence** as in the original GAN.

![GAN architecture](/assets/images/3DGAN-2/GANArchi.png) 

![WGAN Architecture](/assets/images/3DGAN-2/WGANArchi.png)
We can see that in the normal GAN when the discirminator gets its input both from the real data sample and also the fake images , the generator outputs eiter **True or False** that is fake or real. It is a **binary output**. But in WGAN, **the discriminator don't classify  rather for each instance, the discriminator outputs a number**. This number doesn't have to be less than one or greater than zero so we cannot use 0.5 as a threshold to decide whether an instanceis real or not. The WGAN's discriminator training just tries to make the output bigger for real instances and smaller for fake. The WGAN changes the discriminator model with the **critic** that scores the realness or fakeness of a given image.

# How WGAN become IWGAN?

Several study showed that the recent method known as 3DGAN shas the Ability to generate realistic samples of 3D object shapes, categorize 3D shapes, and reconstruct 3D shapes from 2D images. 3DGAN is based on the original generative adversarial network (GAN), an architecture and training approach well known to suffer from instability. While 3DGAN is proficient at producing high-quality objects from single classes, we observed that it is difficult to train on distributions involving multiple distinct object classes in varied poses, because as shown in the following figure, which leads the authors to mainly report the results of independent models, each trained only on a single object category.

![result](/assets/images/3DGAN-2/examplesResult.png)

Therefore, a new approach was studied using the Wasserstein metric explained above (3D-WGAN) and improving it using **autoencoders** to make our 3D-IWGAN model.

![IWGAN architecture](/assets/images/3DGAN-2/architecIWGAN.png)
The VAE contains an encoder that encodes images into latent vectors, and a decoder that generates images from the latent vectors.
The VAE decoder is shared with the GAN generator, so they generate 3D objects from the same latent vectors.
The VAE encoder transforms the input images into latent vectors of dimension 400 sampled from Gaussians.
These latent vectors pass through the decoder/generator to produce a reconstructed 3D object, which is evaluated by the discriminator.

# Conclusion
In summary, this article provided an exploration of the 3D-IWGAN model and its capabilities for 3D object generation and reconstruction from images. We first understood the limitations of the standard GAN model, particularly in terms of training instability. The WGAN model was then presented as a major improvement through the use of the Wasserstein distance as a metric.

We saw how the 3D-IWGAN model leverages the strengths of both the WGAN and VAE models by combining their respective architectures. The addition of a shared encoder and decoder allows for both stable 3D object generation and reconstruction. Experimental results demonstrate the enhanced capacities of the 3D-IWGAN model to handle complex data consisting of multiple object classes.

This article laid the groundwork for understanding adversarial generative models applied to 3D. Many avenues for improvement remain, notably in terms of the realism of synthesized objects. The study of new promising metrics and architectures suggest significant advances are possible in the field of unsupervised learning for 3D shape generation and reconstruction.